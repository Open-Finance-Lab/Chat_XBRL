{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Chrome WebDriver\n",
    "# Make sure to replace 'path/to/chromedriver' with the actual path to your ChromeDriver executable\n",
    "# You can download it from https://chromedriver.chromium.org/downloads\n",
    "\n",
    "Initializes the Chrome WebDriver.\n",
    "Returns:\n",
    "  driver (WebDriver): Selenium WebDriver instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "  service = Service(\"path/to/chromedriver\")  # Update this path\n",
    "  driver = webdriver.Chrome(service=service)\n",
    "  return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "  Automates the scraping process for Nasdaq articles and saves the results to a CSV file.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_nasdaq_articles():\n",
    "  driver = initialize_driver()\n",
    "\n",
    "  try:\n",
    "    # Step 1: Navigate to the Nasdaq homepage\n",
    "    driver.get(\"https://www.nasdaq.com/\")\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Step 2: Click on \"News + Insights\"\n",
    "    news_insights = driver.find_element(By.LINK_TEXT, \"News + Insights\")\n",
    "    ActionChains(driver).move_to_element(news_insights).click().perform()\n",
    "    time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "    # Step 3: Click on \"Stocks\"\n",
    "    stocks_link = driver.find_element(By.LINK_TEXT, \"Stocks\")\n",
    "    stocks_link.click()\n",
    "    time.sleep(5)  # Wait for the Stocks page to load\n",
    "\n",
    "    # Step 4: Scroll down to ensure all articles are loaded\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)  # Allow time for articles to load\n",
    "\n",
    "    # Step 5: Find all article links in the \"Latest News in Stocks\" section\n",
    "    articles = driver.find_elements(By.CSS_SELECTOR, \"a[href^='/articles']\")\n",
    "    article_data = []  # List to store article details\n",
    "\n",
    "    # Loop through each article link\n",
    "    for article in articles:\n",
    "      article_url = article.get_attribute(\"href\")\n",
    "      article_title = article.text\n",
    "\n",
    "      # Navigate to the article URL\n",
    "      driver.get(article_url)\n",
    "      time.sleep(3)  # Wait for the article page to load\n",
    "\n",
    "      # Parse the article HTML content\n",
    "      soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "      html_content = soup.prettify()\n",
    "\n",
    "      # Append data to the list\n",
    "      article_data.append({\n",
    "        \"Article\": article_title,\n",
    "        \"URL\": article_url,\n",
    "        \"HTML Data\": html_content\n",
    "      })\n",
    "\n",
    "    # Step 6: Save the extracted data to a CSV file\n",
    "    df = pd.DataFrame(article_data)\n",
    "    df.to_csv(\"nasdaq_articles.csv\", index=False, encoding=\"utf-8\")\n",
    "    print(\"Data successfully saved to 'nasdaq_articles.csv'\")\n",
    "\n",
    "  finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the scraping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "scrape_nasdaq_articles()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
