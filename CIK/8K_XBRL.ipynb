{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "wjT1m9IJuoJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from xml.etree import ElementTree\n",
        "\n",
        "def get_cik(ticker):\n",
        "    company_name = ticker\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
        "    })\n",
        "\n",
        "    base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "    params = {\n",
        "        \"action\": \"getcompany\",\n",
        "        \"CIK\": ticker,\n",
        "        \"output\": \"xml\"\n",
        "    }\n",
        "\n",
        "    response = session.get(base_url, params=params)\n",
        "\n",
        "    print(f\"URL used for request: {response.url}\")\n",
        "    print(f\"Response Status Code: {response.status_code}\")\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        root = ElementTree.fromstring(response.content)\n",
        "        cik_element = root.find('.//CIK')\n",
        "        if cik_element is not None:\n",
        "            if company_name == 'shortName not found':\n",
        "                company_name = root.find('.//name').text\n",
        "            return cik_element.text, company_name\n",
        "        else:\n",
        "            return \"CIK not found\", company_name\n",
        "    else:\n",
        "        return \"Request failed with status code \" + str(response.status_code), company_name\n",
        "\n",
        "# # Example usage\n",
        "ticker_symbol = \"META\"\n",
        "cik_number, company_name = get_cik(ticker_symbol)\n",
        "print(f\"CIK Number for {company_name}: {cik_number}\")\n",
        "print(f\"Ticker Symbol for {company_name}: {ticker_symbol}\")\n"
      ],
      "metadata": {
        "id": "XQCtEKccj0Fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c83855-e374-4609-f796-06a1094b2cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL used for request: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=META&output=xml\n",
            "Response Status Code: 200\n",
            "CIK Number for META: 0001326801\n",
            "Ticker Symbol for META: META\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def load_8k_xbrl(cik_num=None):\n",
        "    if cik_num is None:\n",
        "        print(\"CIK number is required.\")\n",
        "        return []\n",
        "\n",
        "    url_to_all_8k = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik_num}&type=8-K&dateb=&owner=include&count=100&search_text=\"\n",
        "\n",
        "\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url_to_all_8k, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table = soup.find('table', class_='tableFile2')\n",
        "\n",
        "        if table:\n",
        "            full_links = []\n",
        "            for row in table.find_all('tr')[1:]:  # Skipping the header row\n",
        "                cols = row.find_all('td')\n",
        "                if len(cols) > 3:\n",
        "                    filing_type = cols[0].text.strip()\n",
        "                    filing_date = cols[3].text.strip()\n",
        "\n",
        "                    if filing_type == '8-K':\n",
        "                        doc_link = cols[1].find('a', href=True)['href']\n",
        "                        full_links.append(f\"https://www.sec.gov{doc_link}\")\n",
        "            if full_links:\n",
        "                return full_links\n",
        "            else:\n",
        "                print(\"No 8-K filings.\")\n",
        "                return []\n",
        "        else:\n",
        "            print(\"No table found on the SEC page.\")\n",
        "            return []\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Network error: {e}\")\n",
        "        return []\n",
        "\n",
        "# # Example usage\n",
        "urls = load_8k_xbrl('0000051143')\n",
        "print(urls)"
      ],
      "metadata": {
        "id": "6plvCPwGj0IA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cdb3ff-33bb-458e-bf34-18e452fc1378"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.sec.gov/Archives/edgar/data/51143/000110465924098942/0001104659-24-098942-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000035/0000051143-24-000035-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000033/0000051143-24-000033-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000095015724000918/0000950157-24-000918-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465924057038/0001104659-24-057038-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000021/0000051143-24-000021-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000018/0000051143-24-000018-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000015/0000051143-24-000015-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465924027204/0001104659-24-027204-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465924010040/0001104659-24-010040-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465924009477/0001104659-24-009477-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000007/0000051143-24-000007-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114324000004/0000051143-24-000004-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923125363/0001104659-23-125363-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114323000028/0000051143-23-000028-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114323000026/0000051143-23-000026-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923085847/0001104659-23-085847-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114323000015/0000051143-23-000015-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000005114323000010/0000051143-23-000010-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923072220/0001104659-23-072220-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923052975/0001104659-23-052975-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837023006321/0001558370-23-006321-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837023006218/0001558370-23-006218-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923010509/0001104659-23-010509-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923010504/0001104659-23-010504-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837023000608/0001558370-23-000608-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837023000529/0001558370-23-000529-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465923001206/0001104659-23-001206-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837022015133/0001558370-22-015133-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837022015079/0001558370-22-015079-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465922103516/0001104659-22-103516-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465922099631/0001104659-22-099631-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465922082789/0001104659-22-082789-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837022010829/0001558370-22-010829-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837022010793/0001558370-22-010793-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000095015722000765/0000950157-22-000765-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000110465922053570/0001104659-22-053570-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837022005646/0001558370-22-005646-index.htm', 'https://www.sec.gov/Archives/edgar/data/51143/000155837022005584/0001558370-22-005584-index.htm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import re\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# Function to get XBRL file links from the given SEC page link\n",
        "def get_xbrl_links(link):\n",
        "    session = requests.Session()  # Start a new session\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
        "    }\n",
        "    session.headers.update(headers)  # Set headers for the session\n",
        "\n",
        "    response = session.get(link)  # Get the content of the SEC page\n",
        "    print(f\"Accessing URL: {link}\")\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "\n",
        "    file_links = []  # List to store the XBRL file links\n",
        "    folder_name = None\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')  # Parse the page content\n",
        "\n",
        "        for a_tag in soup.find_all('a', href=True):\n",
        "            file_link = urljoin(link, a_tag['href'])  # Create full URL for the file link\n",
        "\n",
        "            if file_link.endswith(('.xml', '.xsd')):  # Check if the link is a downloadable file\n",
        "                print(f\"Found file link: {file_link}\")\n",
        "                folder_name_new = file_link.split('/')[-1]\n",
        "                folder_name_new = re.split(r'[._]', folder_name_new)[0]\n",
        "\n",
        "                if folder_name is None:\n",
        "                    folder_name = folder_name_new\n",
        "\n",
        "                file_links.append(file_link)  # Add the file link to the list\n",
        "    else:\n",
        "        print(\"Failed to retrieve the webpage\")\n",
        "\n",
        "    return file_links, folder_name\n",
        "\n",
        "# Function to download a file given its link\n",
        "def download_file(session, file_link, folder_name):\n",
        "    for attempt in range(3):  # Try to download up to 3 times\n",
        "        file_response = session.get(file_link)\n",
        "        if file_response.status_code == 200:\n",
        "            file_name = file_link.split('/')[-1]\n",
        "            file_path = os.path.join(folder_name, file_name)\n",
        "            with open(file_path, 'wb') as file:\n",
        "                file.write(file_response.content)  # Write the file content\n",
        "            print(f\"Downloaded: {file_path}\")\n",
        "            return file_path\n",
        "        else:\n",
        "            print(file_response.status_code)\n",
        "            print(f\"Failed to download file: {file_link} (Attempt {attempt + 1})\")\n",
        "    return None\n",
        "\n",
        "# Main function to handle the downloading of SEC files\n",
        "def download_sec_files(link, download_dir):\n",
        "    file_links, folder_name = get_xbrl_links(link)  # Get XBRL links\n",
        "\n",
        "    if not file_links:\n",
        "        print(\"No files to download\")\n",
        "        return folder_name, None\n",
        "\n",
        "    session = requests.Session()  # Start a new session\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
        "    }\n",
        "    session.headers.update(headers)  # Set headers for the session\n",
        "\n",
        "    if not os.path.exists(os.path.join(download_dir, folder_name)):\n",
        "        os.makedirs(os.path.join(download_dir, folder_name))  # Create folder if it doesn't exist\n",
        "\n",
        "    xbrl_name = None\n",
        "\n",
        "    for file_link in file_links:\n",
        "        downloaded_file_path = download_file(session, file_link, os.path.join(download_dir, folder_name))\n",
        "        if downloaded_file_path and '_htm.xml' in downloaded_file_path:\n",
        "            xbrl_name = downloaded_file_path  # Update xbrl_name if the file is the main XBRL file\n",
        "\n",
        "    return folder_name, xbrl_name\n",
        "\n",
        "# Example usage\n",
        "# download_dir = os.path.abspath(\"downloads\")  # Define your download directory\n",
        "# sec_link = 'https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/0001326801-24-000012-index.htm'\n",
        "\n",
        "# folder, xbrl_file = download_sec_files(urls[1], download_dir)\n",
        "# print(f\"Folder: {folder}, XBRL File: {xbrl_file}\")\n"
      ],
      "metadata": {
        "id": "V-i5d-Usj0K8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Usage"
      ],
      "metadata": {
        "id": "Vvru9b6Pur58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of tickers and years\n",
        "\n",
        "# Loop through each ticker and year to download XBRL files\n",
        "\n",
        "''' cik_number;\n",
        "print(f\"CIK Number for {cik_number}\")\n",
        "cik_number = '0001326801'\n",
        "urls = load_8k_xbrl(cik_number)\n",
        "print(f\"URLs for {company_name}: {urls}\") '''\n",
        "\n",
        "input_file_path = '/3_test.txt'\n",
        "\n",
        "''' print(f\"CIK Number for {cik_number}\")\n",
        "cik_number = '0001326801'\n",
        "urls = load_8k_xbrl(cik_number)\n",
        "print(f\"URLs for {company_name}: {urls}\")\n",
        "\n",
        "#download_dir = '.'  # Current working directory\n",
        "download_dir = '/content'\n",
        "for url in (urls):\n",
        "  folder, xbrl_file = download_sec_files(url, download_dir)\n",
        "  print(f\"Folder: {folder}, XBRL File: {xbrl_file}\") '''\n",
        "\n",
        "try:\n",
        "    with open(input_file_path, 'r') as file:\n",
        "        # Loop through each line in the file\n",
        "        for line in file:\n",
        "            cik_number = line.strip()  # Remove any leading/trailing whitespace\n",
        "            print(\"CIK NUMBER CHANGED TO {}\".format(cik_number))\n",
        "            print(f\"CIK Number for {cik_number}\")\n",
        "            urls = load_8k_xbrl(cik_number)\n",
        "            print(f\"URLs for {company_name}: {urls}\")\n",
        "\n",
        "            sub_dir = cik_number\n",
        "            parent_dir = \"/content\"\n",
        "\n",
        "            full_path = os.path.join(parent_dir, sub_dir)\n",
        "\n",
        "            # Create the subdirectory\n",
        "            os.mkdir(full_path)\n",
        "\n",
        "            #download_dir = '.'  # Current working directory\n",
        "            download_dir = full_path\n",
        "            for url in (urls):\n",
        "              folder, xbrl_file = download_sec_files(url, download_dir)\n",
        "              print(f\"Folder: {folder}, XBRL File: {xbrl_file}\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f'Error: The file \"{input_file_path}\" was not found.')\n",
        "except Exception as e:\n",
        "    print(f'An error occurred: {e}')\n",
        "\n",
        "''' download_dir = '.'  # Current working directory\n",
        "for url in (urls):\n",
        "  folder, xbrl_file = download_sec_files(url, download_dir)\n",
        "  print(f\"Folder: {folder}, XBRL File: {xbrl_file}\") '''"
      ],
      "metadata": {
        "id": "5GRNIZG8j0NV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5604d11a-1685-461b-b1ef-60f67ae10de9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file \"/3_test.txt\" was not found.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' download_dir = \\'.\\'  # Current working directory\\nfor url in (urls):\\n  folder, xbrl_file = download_sec_files(url, download_dir)\\n  print(f\"Folder: {folder}, XBRL File: {xbrl_file}\") '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oD0BYq87K6Lv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
